# Discussion {#discussion}

This chapter summarizes the main contributions of the study's research findings to the general field of statistics education. It will focus on how the study has addressed each of the research questions in turn, and offer both further analysis and reflection. It will then articulate some limitations of the research and outline some implications for future research.

The study described in this dissertation examined the change in students' development in reasoning about bivariate data. To measure change in students' reasoning, the quantitative bivariate data scale from the *Assessment Resource Tools for Improving Statistical Thinking* (ARTIST) was administered to 113 students four times during a one-semester introductory statistics course. These students were also assessed on their distributional reasoning four times during the course of the semester using ten items from the *Comprehensive Assessment of Outcomes in a First Statistics course* (CAOS) in order to determine if changes in reasoning about the foundational concepts of distribution were associated with changes in the development of reasoning about bivariate data.

In order to determine if the sequencing of bivariate data within a course is associated with changes in the pattern of change in students' reasoning about bivariate data, the two instructors of the course were used as blocks to randomly assign each section of the course to one of two different course sequences. Both of these course sequences began with the topic of sampling and experimental design followed by exploratory data analysis on univariate distributions. After univariate distribution, one of the course sequences taught the topic of bivariate data and then concluded with topics consisting of sampling distributions, probability, and inference. The other course sequence followed the topic of univariate distribution with those of sampling distributions, probability, and inference with the topic of bivariate data being the last topic taught in the course.

Students were also measured on several other factors to examine if any of them might explain the pattern of change in students' reasoning about bivariate data, and also to serve as controls when comparing the four sections of the course. Ten released items from the 2003 *Trends in International Mathematics and Science Study* (TIMSS) grade-8 mathematics test were administered to students to measure their prior algebra knowledge, and the entire 40-item CAOS was administered to measure prior statistical knowledge. Fifteen survey items that were adapted from the 2005 questionnaire used to examine students' mathematical backgrounds on the grade-12 *National Assessment of Educational Progress* (NAEP) were also given to students to help examine their mathematics background. Lastly, students' ACT composite scores were obtained after the completion of the semester and used as a measure of students’ general knowledge These measures were examined as potential covariates to help explain the pattern in students’ development of reasoning about bivariate data.

To examine the change in students' covariational reasoning, this study utilized linear mixed-effects models (LMMs) in attempt to not only examine the temporal pattern of development, but to determine how that development was influenced by instructional sequence and development in univariate reasoning. In particular, this study sought to answer three research questions:

1. What is the nature, or pattern of change in students' development in reasoning about bivariate data?
2. Is the sequencing of bivariate data within a course associated with changes in the pattern of development in students' reasoning about bivariate data?
3. Are changes in students’ reasoning about the foundational concepts of distribution associated with changes in the pattern of development in students' reasoning about bivariate data?


## Research Question 1

Students in this study seemed to exhibit growth in their reasoning about bivariate data. The LMM that was adopted to examine this growth suggested that students exhibit both linear and quadratic growth in their development about reasoning about bivariate data and that this growth varies among individual students. A quadratic model indicates that students’ reasoning about bivariate data does not increase in a constant linear fashion, but instead increases differentially over time. The significant negative quadratic term suggests that although students initially show great strides in their reasoning about bivariate data, they eventually plane off in this development and over time might actually even regress. This pattern of development, consistent with several different learning theories [e.g., overlapping waves theory\; @siegler:2000], might suggest that a saturation point in bivariate reasoning is reached by students and then decay or interference impedes any more growth in reasoning during the course [e.g., @wixted:2004].

The model also suggested that on average students without any instruction start with very little reasoning about bivariate data and that this is true for nearly all students. This could be because almost all of the students used in this study had never had a previous statistics course. However, the low initial status leaves much to be desired, especially since covariation is recognized and promoted by NCTM in the mathematics curriculum at nearly every age level. This might be explained by the fact that many of these students hadn’t had a mathematics course in several years prior to taking statistics, but it might also be because reasoning is not a major focus of most mathematics courses.

While the fixed-effects and random-effects terms for intercept, linear rate of change and quadratic rate of change were all statistically significant, the practical significance might not be as important. For instance, the variance terms associated with the quadratic rate of change was statistically significant ($p<0.05$) indicating that students vary in their quadratic rates of change. However, the actual variance term was 0.0000121. This small variance component indicates that students' quadratic rates of change are very similar. Also, comparatively, the within-student variance component still accounts for the majority of the variation in BRA scores.

One interesting finding is that most of the change in development in reasoning about bivariate data seemed to occur between the first two measurement occasions. This was before bivariate data was formally taught in either instructional sequence. This might indicate that students' development in reasoning about bivariate data is more an artifact of their development to reason about statistics in general than it is a result of any formal instruction on the topic of bivariate data. However, the brevity of the unit within this particular introductory statistics class (four instructional sessions) might also inhibit an increase in development of reasoning due to instruction about this topic. It also might mean that students' reasoning about bivariate data is closely tied to their reasoning about univariate distribution as suggested by the statistics education literature [e.g., @cobb:2003a; @gravemeijer:2000].

This study has in some sense, broken new ground in the field of statistics education. The literature has, to date, not examined the development of students' reasoning about bivariate data. Perhaps this study could be used as a model for how student development of reasoning could be studied in an introductory statistics course.


## Research Question 2

The sequencing of bivariate data within a course seemed not to be associated with changes in students' development of reasoning about bivariate data either as a solitary covariate, or in conjunction with other covariates. There seemed to be no differences in either the linear or quadratic rates of change in covariational reasoning between the two instructional sequences. The fact that sequencing was not important in explaining patterns of development might not be surprising if, as stated before, reasoning about bivariate data is just a byproduct of reasoning about statistics in general.

Finding no differences in students' reasoning between the two sequences might suggest that the topic could be placed wherever the instructor or textbook authors decided. As a word of caution, however, while the development in reasoning about bivariate data might not change as a result of the placement of this topic, student development of reasoning about other topics might be impacted. One of these topics could be inference. While this wasn’t tested formally in this study, some anecdotal evidence, such as students’ complaints and discussion, suggests that students in the class where bivariate data was taught earlier seemed to be struggling with inference more than students in the other classes. It might also be that bivariate data is a topic that is more “digestible” than inference at the end of a semester.


Course sequencing has also received little attention in the statistics education literature. While Chance and Rossman [-@chance:2001] have speculated about the placement of a unit on bivariate data, there has been no research on optimal placement of this, or for that matter any other topic within an introductory statistics course. The literature on textbook usage has, however, suggested that the content and sequencing of textbooks could influence how effectively students will learn that content [e.g., @valverde:2002]. While this study found no effect on students' growth based on where the unit on bivariate data was placed, research questions involving course content and sequence need more attention.


## Research Question 3

This study initially seemed to suggest that change in reasoning about univariate distribution was not associated with students' development of reasoning about bivariate data. However, once the effects of teacher were controlled for, changes in reasoning about distribution were important in explaining the quadratic rate of change in covariational reasoning. The model suggested students who exhibited higher than average change in their reasoning about univariate distribution tended to also have higher quadratic terms in their patterns of development (the level-1 equations). This indicates that those students will exhibit less loss of reasoning about bivariate data throughout the duration of an introductory statistics course.

While the association between change in reasoning about univariate distribution and quadratic change in reasoning about bivariate data was statistically significant, the practical significance is rather dubious. The coefficient was very small, indicating very little difference in the quadratic rate of change for those students who had a higher than average and those students who had a less than average change in their reasoning about univariate distribution.

There also seemed to be a teacher difference both in initial status (which has nothing to do with the teacher) and in linear rate of change. While linear change in covariational reasoning might be due to the teacher, it could also be that those students who started lower are just catching up so to speak.

The findings from this research question are also somewhat novel. The research literature on students' reasoning about bivariate data has been generally speculative. While Cobb, McClain, and Gravemeijer [-@cobb:2003a] and @@gravemeijer:2000 have all suggested that students need to be able to reason about univariate distribution before they can reason about bivariate data, there have been no studies that have examined this hypothesis. Perhaps the pattern of change in reasoning exhibited by students in this study lends some credence to these speculations. Since most of the growth in reasoning about bivariate data occurred during the instruction of univariate distribution, perhaps these two types of reasoning are inextricably connected.


## Limitations


There are many limitations to this research that need to be mentioned. One limitation concerns both the sample size ($n=113$) and the number of measurement occasions ($t=4$). One hundred thirteen students (level-1 units) is a very small sample size in the realm of multi-level modeling. Small sample sizes may result in less efficiency and power of multilevel tests. With less than adequate power there is an unacceptable risk of not detecting cross-level interactions (e.g., between students and measurement occasions). However, both adequate number of individual observations and adequate number of students are needed, since power for level-1 estimates depends on number of measurement occasions, and power for level-2 estimates depends on number of students.

Generalization may also be limited due to the type of introductory statistics students that were used in the study. These students were typically female social science majors. This does not adequately describe most introductory statistics students. However, while these students may have not been typical in terms of demographics, they might be typical in terms of initial levels of reasoning and background for students enrolled in a non-calculus based first semester statistics course.

Another limitation in this study is the instruments that were utilized. The reliability of scores for the reasoning instruments, while tolerable, could be higher. Also, while most students did not reach the maximum score on the assessments, a few students did get perfect scores. This may have limited the variability in scores and thereby impacted the LMM coefficients. The instruments to measure covariates, such as algebra knowledge, also produced unreliable scores. This might have hindered the identification of differences between groups of students.

Another limitation was the number of students who returned the ACT consent form. While the use of social exchange [@dillman:2000] was thought to increase the response rate, there were still a number of students who opted not to consent to release their ACT score. One possible solution might have been to have students self-report that data, but studies have suggested that students' self-reports of these test scores are not reliable at all [@cassady:2001].

Missing data might also have impacted the findings for the third research question as well. Since only 98 students had measurements on the fourth occasion, the sample was reduced due to the fact that not every student had a difference score (level-2 predictor) for this model. While this missingness was thought to be random (due only to student absence) there is no way for the applied researcher to be sure of this unless he/she had the very data they do not have. Thus, while these observations were identified as missing at random and therefore the model parameters should be un-biased, there is no way to be sure.

Finally, while every effort was made to ensure consistency between the two teachers, much like snowflakes, there are no two instructors who teach the same way. This unavoidable inconsistency might have affected growth in such a way as to "cover up" differences due to one of the tested level-2 predictors. In larger studies this can be accounted for by using a three-level model where not only are measurements nested within students, but students are also nested within teachers. Thus, the variation can be further partitioned and accounted for. However, the small number of teachers ($k=2$) did not allow this type of model to converge in this study.


## Implications for Teaching

While there were many limitations connected with this study, the results suggest some practical implications for teachers of introductory statistics. One implication is that instruction in topics related to univariate distribution (e.g., center, spread) may have great impact on students' reasoning on many other topics within the introductory statistics curriculum. This is shown in the pattern of students' development where the most growth occurred during the instruction of univariate distribution. This importance of univariate distribution is made even more salient by the significance of this factor on the development of students' reasoning about bivariate data. The idea of spending ample time developing students’ reasoning about univariate distribution is also consistent with recommendations in the statistics education literature [e.g., @asa:2005; @iase:2005]

Secondly, the sequencing of topics within an introductory course needs to be given more thought. While this study did not show a change in students' reasoning about bivariate data based on where the unit was sequenced, it might have an effect on students' reasoning about other topics, such as inference. Since so many topics are interconnected in the introductory statistics curriculum, it would make a great deal of sense that the course sequence might affect student reasoning.


## Future Research

There is a great deal of need for research on growth within an introductory statistics course. With the new ASA endorsed GAISE guidelines, the introductory statistics course will change in future years. It is an important educational goal to determine which factors in an introductory statistics course influence students' growth. Is it the teacher? The curriculum? Student interactions? Or is it the individual student?

To this end, one still prominent research question is not only how the placement of a unit on bivariate data influences students' development in covariational reasoning, but how that placement affects the development of reasoning about other topics within an introductory statistics course such as inference. Questions about the best sequencing of curriculum within an introductory statistics course are important not only in how they impact students' learning and reasoning about statistics in general, but in how those sequences impact students’ reasoning of sub-topics within a course.

Another interesting line of research is how foundational topics in an introductory statistics course influence students' development of reasoning about other topics. While this study examined how changes in students’ reasoning about distribution influenced their reasoning about bivariate data, perhaps a different study might look at how students' reasoning about variation might influence reasoning about bivariate data or other statistical reasoning.

Researchers interested in change in students' reasoning about statistical concepts might use this as a springboard. This study has employed a methodology that allows researchers to examine students' development of reasoning in an introductory statistics course in the ecology of an actual classroom. It has also made an attempt at using randomization in classroom research. While far from the ideal of educational research, this study may provide statistics education researchers with insight and direction in terms of design and methodology. The results of this study may also suggest some future research in the study of students' development of statistical reasoning. For instance, it seems that much of the variation in students' change in reasoning is within-student variation. This implies the need to add a time-varying (level-1) predictor. It would be worthwhile for researchers to consider what predictors at level-1 might account for this variation. Likewise, on average students did not differ on many of the level-2 covariates. It would be wise for statistics educators to identify predictors that may account for the level-2 variation. While these might be difficult to identify *a priori*, the research literature may provide some guidance. For instance, many studies have suggested that prior mathematics and statistics experience are not predictive of students' ability to reason [e.g., @konold:1999].

Future researchers might want to use a non-linear model to depict student development. Non-linear models have been used to model change in student development [e.g., @mcardle:1987]. This might be more in line with learning theory [e.g., @min:2000; @murre:2006; @wozniak:1990]. For instance, the use of the logistic curve to model population growth [@verhulst:1845] was adapted by @pearl:1925 to model cognitive growth. Another example of non-linear growth to describe learning is the hyperbolic curve outlined by @thurston:1919.

In summary, the study of change of students' reasoning requires multiple measurements over time. The current methodologies used to study change (e.g., structural equation modeling, multi-level modeling) require the same assessment to be used at each time point. This is generally not pedagogically acceptable to most college teachers given the time constraints that accompany collegiate courses. Even more complicated is the fact that to model a complex growth pattern requires more measurement occasions, especially during times that students are exhibiting the most change, such as near the beginning of the semester [@willett:1989; @willet:1998]. This frequent testing could have a negative impact on student attitudes and cause early fatigue in study subjects. As the call for growth studies by policy makers and interested parties increases, careful attention should be given to the methodologies and the practical problems faced by educators in their implementation.



